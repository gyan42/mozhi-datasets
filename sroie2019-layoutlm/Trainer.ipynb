{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BinXhITfVFGp"
      },
      "source": [
        "Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZOTBCOMUj1j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4beee4f-0f30-4820-e1fd-e1d7f454c9e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 306 kB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 61 kB 451 kB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 50.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 243 kB 74.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 132 kB 68.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 50.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 192 kB 58.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 271 kB 57.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 160 kB 56.2 MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets seqeval --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLWcDQ528zEE",
        "outputId": "cd8cef8d-e747-4f09-8775-61449cabf494"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "input_ids  = [101, 9092, 15854, 2078, 13619, 2078, 2338, 11937, 1012, 1047, 1006, 17214, 2319, 2154, 2050, 1007, 17371, 2078, 24869, 2094, 6275, 2683, 23632, 2581, 1011, 1059, 2053, 1012, 5187, 4583, 5401, 1004, 5354, 28410, 7842, 12193, 2324, 17214, 2319, 2154, 2050, 6282, 18613, 25268, 8670, 8093, 2226, 25268, 1012, 6254, 2053, 1024, 14595, 24096, 16048, 2581, 10790, 2549, 3058, 1024, 2423, 1013, 2260, 1013, 2760, 1022, 1024, 2410, 1024, 4464, 7610, 5356, 3771, 1024, 23624, 2015, 2266, 1024, 5356, 3021, 3642, 1013, 4078, 2278, 3976, 5860, 3815, 1053, 3723, 28549, 5345, 26976, 2683, 23499, 2692, 12740, 14526, 2575, 1047, 2546, 19518, 5726, 25358, 2100, 3869, 1015, 7473, 1008, 1023, 1012, 2199, 1014, 1012, 4002, 1023, 1012, 4002, 2561, 1024, 20996, 3126, 22033, 19037, 1024, 2461, 1040, 2561, 1006, 28549, 1007, 1024, 5356, 2184, 1012, 4002, 2689, 1015, 1012, 4002, 5350, 2853, 2024, 2025, 2709, 3085, 2030, 3863, 3085, 1008, 1008, 1008, 4067, 2017, 3531, 2272, 2153, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "tokens = ['[CLS]', 'tan', 'woo', '##n', 'yan', '##n', 'book', 'ta', '.', 'k', '(', 'tam', '##an', 'day', '##a', ')', 'sd', '##n', 'bn', '##d', '78', '##9', '##41', '##7', '-', 'w', 'no', '.', '53', '55', '57', '&', '59', 'jalan', 'sa', '##gu', '18', 'tam', '##an', 'day', '##a', '81', '##100', 'johor', 'ba', '##hr', '##u', 'johor', '.', 'document', 'no', ':', 'td', '##01', '##16', '##7', '##10', '##4', 'date', ':', '25', '/', '12', '/', '2018', '8', ':', '13', ':', '39', 'pm', 'cash', '##ier', ':', 'mani', '##s', 'member', ':', 'cash', 'bill', 'code', '/', 'des', '##c', 'price', 'disc', 'amount', 'q', '##ty', 'rm', '95', '##56', '##9', '##39', '##0', '##40', '##11', '##6', 'k', '##f', 'modelling', 'clay', 'kidd', '##y', 'fish', '1', 'pc', '*', '9', '.', '000', '0', '.', '00', '9', '.', '00', 'total', ':', 'ro', '##ur', 'ding', 'adjustment', ':', 'round', 'd', 'total', '(', 'rm', ')', ':', 'cash', '10', '.', '00', 'change', '1', '.', '00', 'goods', 'sold', 'are', 'not', 'return', '##able', 'or', 'exchange', '##able', '*', '*', '*', 'thank', 'you', 'please', 'come', 'again', '!', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
        "bbox  = [[0, 0, 0, 0], [117, 21, 530, 52], [117, 21, 530, 52], [117, 21, 530, 52], [117, 21, 530, 52], [117, 21, 530, 52], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [82, 67, 715, 98], [333, 98, 463, 113], [333, 98, 463, 113], [333, 98, 463, 113], [333, 98, 463, 113], [333, 98, 463, 113], [333, 98, 463, 113], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [179, 117, 622, 132], [312, 137, 486, 151], [312, 137, 486, 151], [312, 137, 486, 151], [312, 137, 486, 151], [263, 156, 543, 171], [263, 156, 543, 171], [263, 156, 543, 171], [263, 156, 543, 171], [263, 156, 543, 171], [263, 156, 543, 171], [353, 175, 447, 188], [353, 175, 447, 188], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 276, 453, 290], [82, 300, 156, 315], [82, 300, 156, 315], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [268, 300, 556, 314], [78, 320, 190, 335], [78, 320, 190, 335], [78, 320, 190, 335], [267, 321, 350, 334], [267, 321, 350, 334], [80, 342, 199, 355], [80, 342, 199, 355], [311, 371, 484, 384], [311, 371, 484, 384], [49, 410, 197, 422], [49, 410, 197, 422], [49, 410, 197, 422], [49, 410, 197, 422], [325, 409, 401, 421], [449, 409, 497, 421], [608, 409, 716, 421], [113, 429, 166, 444], [113, 429, 166, 444], [682, 427, 720, 442], [44, 460, 223, 471], [44, 460, 223, 471], [44, 460, 223, 471], [44, 460, 223, 471], [44, 460, 223, 471], [44, 460, 223, 471], [44, 460, 223, 471], [44, 460, 223, 471], [259, 460, 643, 471], [259, 460, 643, 471], [259, 460, 643, 471], [259, 460, 643, 471], [259, 460, 643, 471], [259, 460, 643, 471], [259, 460, 643, 471], [125, 483, 184, 495], [125, 483, 184, 495], [225, 482, 241, 490], [328, 482, 398, 494], [328, 482, 398, 494], [328, 482, 398, 494], [663, 540, 720, 552], [663, 540, 720, 552], [663, 540, 720, 552], [669, 516, 718, 528], [669, 516, 718, 528], [669, 516, 718, 528], [398, 516, 476, 531], [398, 516, 476, 531], [192, 542, 473, 555], [192, 542, 473, 555], [192, 542, 473, 555], [192, 542, 473, 555], [192, 542, 473, 555], [140, 568, 475, 584], [140, 568, 475, 584], [140, 568, 475, 584], [140, 568, 475, 584], [140, 568, 475, 584], [140, 568, 475, 584], [140, 568, 475, 584], [333, 600, 395, 617], [653, 604, 716, 616], [653, 604, 716, 616], [653, 604, 716, 616], [333, 621, 440, 636], [669, 623, 720, 634], [669, 623, 720, 634], [669, 623, 720, 634], [158, 682, 651, 694], [158, 682, 651, 694], [158, 682, 651, 694], [158, 682, 651, 694], [158, 682, 651, 694], [158, 682, 651, 694], [158, 682, 651, 694], [309, 697, 502, 710], [309, 697, 502, 710], [223, 729, 570, 742], [223, 729, 570, 742], [223, 729, 570, 742], [328, 760, 475, 774], [328, 760, 475, 774], [265, 776, 536, 788], [265, 776, 536, 788], [265, 776, 536, 788], [265, 776, 536, 788], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000], [1000, 1000, 1000, 1000]]\n",
        "\n",
        "\n",
        "token_labels  = [-100, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 0, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
        "\n",
        "\n",
        "tags = ['UNK', 'O', 'O', 'O', 'O', 'O', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'company', 'O', 'O', 'O', 'O', 'O', 'O', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'address', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'date', 'date', 'date', 'date', 'date', 'date', 'date', 'date', 'date', 'date', 'date', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'total', 'total', 'total', 'O', 'O', 'O', 'total', 'total', 'total', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']\n",
        "\n",
        "\n",
        "attention_mask  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "\n",
        "\n",
        "\n",
        "input_ids=torch.Tensor(input_ids).unsqueeze(0).type(torch.LongTensor)\n",
        "bbox=torch.Tensor(bbox).unsqueeze(0).type(torch.LongTensor)\n",
        "attention_mask=torch.Tensor(attention_mask).unsqueeze(0).type(torch.LongTensor)\n",
        "token_type_ids=None\n",
        "labels=torch.Tensor(token_labels).unsqueeze(0).type(torch.LongTensor)\n",
        "\n",
        "input_ids.shape, bbox.shape, attention_mask.shape, labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgAo-d2PNMi8",
        "outputId": "20692757-f312-41f4-da08-ae603793fddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 512]),\n",
              " torch.Size([1, 512, 4]),\n",
              " torch.Size([1, 512]),\n",
              " torch.Size([1, 512]))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LayoutLMTokenizer, LayoutLMForTokenClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = LayoutLMTokenizer.from_pretrained('microsoft/layoutlm-base-uncased')\n",
        "model = LayoutLMForTokenClassification.from_pretrained('microsoft/layoutlm-base-uncased', num_labels=5)\n",
        "\n",
        "outputs = model(input_ids=input_ids, bbox=bbox, attention_mask=attention_mask, token_type_ids=None,\n",
        "                 labels=labels)\n",
        "\n",
        "loss = outputs.loss\n",
        "logits = outputs.logits\n",
        "\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRVAsiNxjKmW",
        "outputId": "a6805b6f-7654-4efa-879b-b66110fe806c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.2755, -0.2073, -0.1129, -0.3306, -0.1537],\n",
            "         [-0.1487,  0.1903, -0.1550,  0.0108, -0.0314],\n",
            "         [-0.0726,  0.5937, -0.1306,  0.0731,  0.3635],\n",
            "         ...,\n",
            "         [-0.1185,  0.1908, -0.0952,  0.3960, -0.4811],\n",
            "         [-0.1185,  0.1908, -0.0952,  0.3960, -0.4811],\n",
            "         [-0.1185,  0.1908, -0.0952,  0.3960, -0.4811]]],\n",
            "       grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOUJ150TVIaD"
      },
      "source": [
        "Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3nyyy3KUomg",
        "outputId": "6de90a13-11ae-40d0-d641-27390a944144"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'mozhi-datasets' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gyan42/mozhi-datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd mozhi-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpwsOP7jx4TD",
        "outputId": "6c2c1291-a27f-4d98-b0f5-2b1604ad9c06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mozhi-datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMnkb-A9bs7P",
        "outputId": "da6ad279-7c27-4fe1-e7c3-9e4c9273eaf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqHDRGXNVPbL"
      },
      "source": [
        "Check and change the directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DobDmJXEU02Y",
        "outputId": "a400337a-facd-4598-e9ae-9a86aced88c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataPreprocessing.ipynb  README.md\n",
            "hf_model_train.py\t Roboto-Light.ttf\n",
            "hf_tokenize.py\t\t SREIO2019LayoutLMTraining.ipynb\n",
            "layoutlm-sreio2019\t sroie2019_layoutlm_dataset.py\n",
            "__pycache__\t\t version1\n"
          ]
        }
      ],
      "source": [
        "! ls sroie2019-layoutlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfiICVXNU7lk",
        "outputId": "54e53f79-300b-4c60-ce9c-1373ac9c8ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mozhi-datasets/sroie2019-layoutlm\n"
          ]
        }
      ],
      "source": [
        "% cd sroie2019-layoutlm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5nPZCr2VAks",
        "outputId": "2ffe8356-3a1f-49a5-ca23-026a3ce69ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataPreprocessing.ipynb  README.md\n",
            "hf_model_train.py\t Roboto-Light.ttf\n",
            "hf_tokenize.py\t\t SREIO2019LayoutLMTraining.ipynb\n",
            "layoutlm-sreio2019\t sroie2019_layoutlm_dataset.py\n",
            "__pycache__\t\t version1\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_Waf_RSVDc6",
        "outputId": "8b200139-8da3-4bf2-8745-c782a82092cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache directory:  /root/.mozhi\n",
            "Cache1 directory:  /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0\n",
            "Reusing dataset sroie2019_layout_lm (/root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0)\n",
            "\r  0% 0/3 [00:00<?, ?it/s]\r100% 3/3 [00:00<00:00, 651.76it/s]\n",
            "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-3e45bf19d9062fab.arrow\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-6002277219670457.arrow\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-67c4e1377a0974f4.arrow\n",
            "The following columns in the training set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: bboxes, ner_tags, id, tokens.\n",
            "***** Running training *****\n",
            "  Num examples = 545\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 345\n",
            " 20% 69/345 [02:25<07:27,  1.62s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: bboxes, ner_tags, id, tokens.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 41\n",
            "  Batch size = 8\n",
            "Traceback (most recent call last):\n",
            "  File \"hf_model_train.py\", line 100, in <module>\n",
            "    trainer.train()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1414, in train\n",
            "    self._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1521, in _maybe_log_save_evaluate\n",
            "    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 2165, in evaluate\n",
            "    metric_key_prefix=metric_key_prefix,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 2332, in evaluation_loop\n",
            "    loss, logits, labels = self.prediction_step(model, inputs, prediction_loss_only, ignore_keys=ignore_keys)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 2537, in prediction_step\n",
            "    loss, outputs = self.compute_loss(model, inputs, return_outputs=True)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\", line 1923, in compute_loss\n",
            "    outputs = model(**inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/layoutlm/modeling_layoutlm.py\", line 1184, in forward\n",
            "    return_dict=return_dict,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/layoutlm/modeling_layoutlm.py\", line 824, in forward\n",
            "    inputs_embeds=inputs_embeds,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/models/layoutlm/modeling_layoutlm.py\", line 126, in forward\n",
            "    + token_type_embeddings\n",
            "RuntimeError: The size of tensor a (450) must match the size of tensor b (451) at non-singleton dimension 1\n",
            " 20% 69/345 [02:26<09:44,  2.12s/it]\n"
          ]
        }
      ],
      "source": [
        "!CUDA_LAUNCH_BLOCKING=1 python hf_model_train.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "dyR8i1t94KsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0c3DFe8O8qMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sCo2yE0g8qKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "snlEFe8E8qHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mnxe-egk8qFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BFwdjebS8qCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cDKPyYB38p_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ws8Yh2CN8p8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trail code from here"
      ],
      "metadata": {
        "id": "wwYEGtFxB3uR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "h0rEfc-18pwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from hf_tokenize import HFTokenizer\n",
        "from sroie2019_layoutlm_dataset import HFSREIO2019LayoutLMDataset"
      ],
      "metadata": {
        "id": "2w1h6VA__sv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import transformers\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, AutoTokenizer\n",
        "from transformers import LayoutLMForTokenClassification\n",
        "import torch\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from datasets import load_dataset, load_metric\n",
        "# Ref: https://github.com/huggingface/datasets/blob/master/datasets/conll2003/conll2003.py\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import datasets\n",
        "from datasets import DownloadConfig\n",
        "import os\n",
        "from pathlib import Path\n",
        "from datasets import load_dataset, ClassLabel, DownloadConfig\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from hf_tokenize import HFTokenizer\n",
        "from sroie2019_layoutlm_dataset import HFSREIO2019LayoutLMDataset\n",
        "\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "logger = datasets.logging.get_logger(__name__)\n"
      ],
      "metadata": {
        "id": "tMYAEcyn_8Gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_metrics(p, label_list):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "QMEWXoWB_zb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " hf_pretrained_tokenizer_checkpoint = \"distilbert-base-uncased\""
      ],
      "metadata": {
        "id": "VvkKRcL6Ac-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_dataset = HFSREIO2019LayoutLMDataset()\n",
        "hf_preprocessor = HFTokenizer.init_vf(hf_pretrained_tokenizer_checkpoint=hf_pretrained_tokenizer_checkpoint)\n",
        "\n",
        "#     hf_model = AutoModelForTokenClassification.from_pretrained(hf_pretrained_model_checkpoint,\n",
        "#                                                             num_labels=len(hf_dataset.labels))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "hf_model = LayoutLMForTokenClassification.from_pretrained(\"microsoft/layoutlm-base-uncased\", num_labels=5)\n",
        "# hf_model.to(device)\n",
        "\n",
        "\n",
        "hf_model.config.id2label = hf_dataset.id2label\n",
        "hf_model.config.label2id = hf_dataset.label2id\n",
        "\n",
        "tokenized_datasets = hf_dataset.dataset.map(hf_preprocessor.tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260,
          "referenced_widgets": [
            "47803ee4fe764ed78b6f9c05972db383",
            "6ccf9e92376441b98b153d9eba72c9dc",
            "2223c0c2b1b34939b918b0a75531436a",
            "935c13f2c6024df9bd0e5e2ecd73e173",
            "77229a232cbf4c0cad17a334cfe9cbf8",
            "46e2b8904d4643fa9ae99169e8882b7a",
            "a547322a5ff5455987eb64ef189a504f",
            "1ad5207055bf4527b82edaf49943ad3a",
            "8882a3454fd04c3b9e5cf59f4937e001",
            "d2339462e4934afb904c6b3c73f52720",
            "719b9e24d7334f1388cc5cad112fc505"
          ]
        },
        "id": "KKJyvc1FAXhd",
        "outputId": "7c8ccba4-d7c0-4552-e067-d3a115cea1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset sroie2019_layout_lm (/root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache directory:  /root/.mozhi\n",
            "Cache1 directory:  /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47803ee4fe764ed78b6f9c05972db383",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-3e45bf19d9062fab.arrow\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-6002277219670457.arrow\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-67c4e1377a0974f4.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4bQ7Sub8_jf",
        "outputId": "75859a80-554f-4f2d-d24c-7d41955c2a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['attention_mask', 'bbox', 'bboxes', 'id', 'input_ids', 'labels', 'ner_tags', 'tokens'],\n",
              "        num_rows: 545\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['attention_mask', 'bbox', 'bboxes', 'id', 'input_ids', 'labels', 'ner_tags', 'tokens'],\n",
              "        num_rows: 41\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['attention_mask', 'bbox', 'bboxes', 'id', 'input_ids', 'labels', 'ner_tags', 'tokens'],\n",
              "        num_rows: 81\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(range(0, 587, 32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU7hWQ_i3Y5S",
        "outputId": "66d92001-7212-4257-9641-597108d14fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0,\n",
              " 32,\n",
              " 64,\n",
              " 96,\n",
              " 128,\n",
              " 160,\n",
              " 192,\n",
              " 224,\n",
              " 256,\n",
              " 288,\n",
              " 320,\n",
              " 352,\n",
              " 384,\n",
              " 416,\n",
              " 448,\n",
              " 480,\n",
              " 512,\n",
              " 544,\n",
              " 576]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_dataloader():\n",
        "     for i in range(0, 545 - (545 % 32), 32):\n",
        "        yield tokenized_datasets['train'][i:i+32]"
      ],
      "metadata": {
        "id": "B7_ZDR_qA7n_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader():\n",
        "  print(torch.tensor(batch['input_ids']).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onOL8dsTDKoy",
        "outputId": "36aaf7dd-0fe7-4f34-ed80-4cd69ccf79dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n",
            "torch.Size([32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "id": "mZCHpxPlF6iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader():\n",
        "    input_ids = torch.Tensor(batch['input_ids']).type(torch.LongTensor)\n",
        "    bbox = torch.Tensor(batch['bbox']).type(torch.LongTensor)\n",
        "    attention_mask = torch.Tensor(batch['attention_mask'])\n",
        "    # token_type_ids = batch['token_type_ids'].to(device)\n",
        "    labels = torch.Tensor(batch['labels']).type(torch.LongTensor)\n",
        "\n",
        "    print(\"shapes.....\")\n",
        "    print(input_ids.shape, bbox.shape, attention_mask.shape, labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyHnL1bqZw1s",
        "outputId": "4516db66-ce60-4852-bbca-6da7f5746f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n",
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOcpoqlh4Af6",
        "outputId": "4e076a78-12e5-4bc1-8b8f-d0532b53ed26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrMrCOd0VjBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c3c4d1-c01b-4354-a3c5-318af56c2d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shapes.....\n",
            "torch.Size([32, 512]) torch.Size([32, 512, 4]) torch.Size([32, 512]) torch.Size([32, 512])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "optimizer = AdamW(hf_model.parameters(), lr=5e-5)\n",
        "\n",
        "global_step = 0\n",
        "num_train_epochs = 15\n",
        "# t_total = len(train_dataloader) * num_train_epochs # total number of training steps \n",
        "\n",
        "#put the model in training mode\n",
        "hf_model.train()\n",
        "for epoch in range(num_train_epochs):\n",
        "  for batch in train_dataloader():\n",
        "      input_ids = torch.Tensor(batch['input_ids']).type(torch.LongTensor)\n",
        "      bbox = torch.Tensor(batch['bbox']).type(torch.LongTensor)\n",
        "      attention_mask = torch.Tensor(batch['attention_mask'])\n",
        "      # token_type_ids = batch['token_type_ids'].to(device)\n",
        "      labels = torch.Tensor(batch['labels']).type(torch.LongTensor)\n",
        "\n",
        "      print(\"shapes.....\")\n",
        "      print(input_ids.shape, bbox.shape, attention_mask.shape, labels.shape)\n",
        "      # forward pass\n",
        "      outputs = hf_model(input_ids=input_ids, \n",
        "                         bbox=bbox, \n",
        "                         attention_mask=attention_mask, \n",
        "                        #  token_type_ids=token_type_ids,\n",
        "                          labels=labels)\n",
        "      loss = outputs.loss\n",
        "\n",
        "      # print loss every 100 steps\n",
        "      if global_step % 100 == 0:\n",
        "        print(f\"Loss after {global_step} steps: {loss.item()}\")\n",
        "\n",
        "      # backward pass to get the gradients \n",
        "      loss.backward()\n",
        "\n",
        "      #print(\"Gradients on classification head:\")\n",
        "      #print(model.classifier.weight.grad[6,:].sum())\n",
        "\n",
        "      # update\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      global_step += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "k7JZbJvNV4P7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Trainer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "47803ee4fe764ed78b6f9c05972db383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ccf9e92376441b98b153d9eba72c9dc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2223c0c2b1b34939b918b0a75531436a",
              "IPY_MODEL_935c13f2c6024df9bd0e5e2ecd73e173",
              "IPY_MODEL_77229a232cbf4c0cad17a334cfe9cbf8"
            ]
          }
        },
        "6ccf9e92376441b98b153d9eba72c9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2223c0c2b1b34939b918b0a75531436a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46e2b8904d4643fa9ae99169e8882b7a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a547322a5ff5455987eb64ef189a504f"
          }
        },
        "935c13f2c6024df9bd0e5e2ecd73e173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1ad5207055bf4527b82edaf49943ad3a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8882a3454fd04c3b9e5cf59f4937e001"
          }
        },
        "77229a232cbf4c0cad17a334cfe9cbf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d2339462e4934afb904c6b3c73f52720",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 55.31it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_719b9e24d7334f1388cc5cad112fc505"
          }
        },
        "46e2b8904d4643fa9ae99169e8882b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a547322a5ff5455987eb64ef189a504f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ad5207055bf4527b82edaf49943ad3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8882a3454fd04c3b9e5cf59f4937e001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d2339462e4934afb904c6b3c73f52720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "719b9e24d7334f1388cc5cad112fc505": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}