{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SREIO2019LayoutLMTraining.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages"
      ],
      "metadata": {
        "id": "BinXhITfVFGp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZOTBCOMUj1j",
        "outputId": "e9c44523-fffa-4d48-a3cc-7a943c32adb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.14.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.3 MB/s \n",
            "\u001b[?25hCollecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 474 kB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 24.9 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 31.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 44.0 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 33.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 37.9 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=272b0f6024485be2c7688553f59025afaf3f15695b7b23bb564f2f13c3b57a77\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, pyyaml, fsspec, aiohttp, xxhash, tokenizers, sacremoses, huggingface-hub, transformers, seqeval, datasets\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 pyyaml-6.0 sacremoses-0.0.46 seqeval-1.2.2 tokenizers-0.10.3 transformers-4.14.1 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "! pip install transformers datasets seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clone the repo"
      ],
      "metadata": {
        "id": "wOUJ150TVIaD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gyan42/mozhi-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3nyyy3KUomg",
        "outputId": "099543ad-1886-4812-f232-bc11321e1249"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mozhi-datasets'...\n",
            "remote: Enumerating objects: 78, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 78 (delta 41), reused 50 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check and change the directory"
      ],
      "metadata": {
        "id": "gqHDRGXNVPbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! ls mozhi-datasets/sroie2019-layoutlm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DobDmJXEU02Y",
        "outputId": "97e1d07e-11a5-4f84-e688-df83b7b23734"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataPreprocessing.ipynb  README.md\t\t\tversion1\n",
            "hf_model_train.py\t Roboto-Light.ttf\n",
            "hf_tokenize.py\t\t sroie2019_layoutlm_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "% cd mozhi-datasets/sroie2019-layoutlm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfiICVXNU7lk",
        "outputId": "a896de5a-6aa1-4f7e-c219-7845799ef28f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mozhi-datasets/sroie2019-layoutlm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5nPZCr2VAks",
        "outputId": "8eb0f4fd-c48b-453e-e5a4-09ffbe52372c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataPreprocessing.ipynb  README.md\t\t\tversion1\n",
            "hf_model_train.py\t Roboto-Light.ttf\n",
            "hf_tokenize.py\t\t sroie2019_layoutlm_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python hf_model_train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_Waf_RSVDc6",
        "outputId": "6aaa6a7f-c9ca-41b2-e8d0-c66fcfbe12f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache directory:  /root/.mozhi\n",
            "Cache1 directory:  /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0\n",
            "Reusing dataset sroie2019_layout_lm (/root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0)\n",
            "\r  0% 0/3 [00:00<?, ?it/s]\r100% 3/3 [00:00<00:00, 320.06it/s]\n",
            "Some weights of the model checkpoint at microsoft/layoutlm-base-uncased were not used when initializing LayoutLMForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlm-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-c827562903432b8a.arrow\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-bda3f28779af3dfd.arrow\n",
            "Loading cached processed dataset at /root/.mozhi/sroie2019_layout_lm/SROIE2019LayoutLM/1.0.0/cache-b157044939919284.arrow\n",
            "The following columns in the training set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running training *****\n",
            "  Num examples = 588\n",
            "  Num Epochs = 50\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3700\n",
            "  2% 74/3700 [01:20<59:27,  1.02it/s]  The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.32it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.93it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.98it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.25667673349380493, 'eval_precision': 0.32934131736526945, 'eval_recall': 0.2619047619047619, 'eval_f1': 0.2917771883289125, 'eval_accuracy': 0.9297432239657631, 'eval_runtime': 2.6618, 'eval_samples_per_second': 18.409, 'eval_steps_per_second': 2.63, 'epoch': 1.0}\n",
            "  2% 74/3700 [01:22<59:27,  1.02it/s]\n",
            "100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n",
            "  4% 148/3700 [02:43<54:15,  1.09it/s]  The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.05it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.06it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.19875800609588623, 'eval_precision': 0.3698630136986301, 'eval_recall': 0.38571428571428573, 'eval_f1': 0.37762237762237766, 'eval_accuracy': 0.9436519258202568, 'eval_runtime': 2.3961, 'eval_samples_per_second': 20.45, 'eval_steps_per_second': 2.921, 'epoch': 2.0}\n",
            "  4% 148/3700 [02:45<54:15,  1.09it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            "  6% 222/3700 [04:06<58:07,  1.00s/it]  The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.15it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.92it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.06it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.1182735413312912, 'eval_precision': 0.502262443438914, 'eval_recall': 0.5285714285714286, 'eval_f1': 0.5150812064965198, 'eval_accuracy': 0.9627318116975749, 'eval_runtime': 2.4182, 'eval_samples_per_second': 20.263, 'eval_steps_per_second': 2.895, 'epoch': 3.0}\n",
            "  6% 222/3700 [04:09<58:07,  1.00s/it]\n",
            "100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n",
            "  8% 296/3700 [05:29<48:17,  1.17it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.34it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.00it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.10795564204454422, 'eval_precision': 0.5852534562211982, 'eval_recall': 0.6047619047619047, 'eval_f1': 0.5948477751756441, 'eval_accuracy': 0.967546362339515, 'eval_runtime': 2.6948, 'eval_samples_per_second': 18.183, 'eval_steps_per_second': 2.598, 'epoch': 4.0}\n",
            "  8% 296/3700 [05:32<48:17,  1.17it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 10% 370/3700 [06:53<51:11,  1.08it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.16it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.91it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.07it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.10690786689519882, 'eval_precision': 0.6089108910891089, 'eval_recall': 0.5857142857142857, 'eval_f1': 0.5970873786407767, 'eval_accuracy': 0.9708452211126961, 'eval_runtime': 2.408, 'eval_samples_per_second': 20.349, 'eval_steps_per_second': 2.907, 'epoch': 5.0}\n",
            " 10% 370/3700 [06:55<51:11,  1.08it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 12% 444/3700 [08:17<51:28,  1.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.33it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.99it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.11581291258335114, 'eval_precision': 0.6457399103139013, 'eval_recall': 0.6857142857142857, 'eval_f1': 0.6651270207852195, 'eval_accuracy': 0.9698644793152639, 'eval_runtime': 2.399, 'eval_samples_per_second': 20.425, 'eval_steps_per_second': 2.918, 'epoch': 6.0}\n",
            " 12% 444/3700 [08:19<51:28,  1.05it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            "{'loss': 0.1533, 'learning_rate': 1.72972972972973e-05, 'epoch': 6.76}\n",
            " 14% 500/3700 [09:20<53:37,  1.01s/it]Saving model checkpoint to test-ner/checkpoint-500\n",
            "Configuration saved in test-ner/checkpoint-500/config.json\n",
            "Model weights saved in test-ner/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-500/special_tokens_map.json\n",
            " 14% 518/3700 [09:45<50:52,  1.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.30it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.96it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.97it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.109127938747406, 'eval_precision': 0.6391304347826087, 'eval_recall': 0.7, 'eval_f1': 0.6681818181818182, 'eval_accuracy': 0.9718259629101283, 'eval_runtime': 2.4207, 'eval_samples_per_second': 20.242, 'eval_steps_per_second': 2.892, 'epoch': 7.0}\n",
            " 14% 518/3700 [09:48<50:52,  1.04it/s]\n",
            "100% 7/7 [00:02<00:00,  2.97it/s]\u001b[A\n",
            " 16% 592/3700 [11:08<42:31,  1.22it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.24it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.07it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.1260756403207779, 'eval_precision': 0.5697674418604651, 'eval_recall': 0.7, 'eval_f1': 0.6282051282051283, 'eval_accuracy': 0.9667439372325249, 'eval_runtime': 2.4221, 'eval_samples_per_second': 20.23, 'eval_steps_per_second': 2.89, 'epoch': 8.0}\n",
            " 16% 592/3700 [11:10<42:31,  1.22it/s]\n",
            "100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n",
            " 18% 666/3700 [12:30<48:45,  1.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.20it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.94it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.10it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.12365707755088806, 'eval_precision': 0.6434782608695652, 'eval_recall': 0.7047619047619048, 'eval_f1': 0.6727272727272727, 'eval_accuracy': 0.9695970042796006, 'eval_runtime': 2.3849, 'eval_samples_per_second': 20.546, 'eval_steps_per_second': 2.935, 'epoch': 9.0}\n",
            " 18% 666/3700 [12:32<48:45,  1.04it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 20% 740/3700 [13:54<45:13,  1.09it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.36it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.05it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.13245682418346405, 'eval_precision': 0.6115702479338843, 'eval_recall': 0.7047619047619048, 'eval_f1': 0.6548672566371682, 'eval_accuracy': 0.967546362339515, 'eval_runtime': 2.3825, 'eval_samples_per_second': 20.567, 'eval_steps_per_second': 2.938, 'epoch': 10.0}\n",
            " 20% 740/3700 [13:56<45:13,  1.09it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 22% 814/3700 [15:16<48:56,  1.02s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.26it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.92it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.12645357847213745, 'eval_precision': 0.6188524590163934, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6651982378854625, 'eval_accuracy': 0.968348787446505, 'eval_runtime': 2.4076, 'eval_samples_per_second': 20.352, 'eval_steps_per_second': 2.907, 'epoch': 11.0}\n",
            " 22% 814/3700 [15:19<48:56,  1.02s/it]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 24% 888/3700 [16:39<45:05,  1.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.18it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.96it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.14708590507507324, 'eval_precision': 0.616, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.6695652173913044, 'eval_accuracy': 0.9684379457917262, 'eval_runtime': 2.4414, 'eval_samples_per_second': 20.07, 'eval_steps_per_second': 2.867, 'epoch': 12.0}\n",
            " 24% 888/3700 [16:41<45:05,  1.04it/s]\n",
            "100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n",
            " 26% 962/3700 [18:02<41:37,  1.10it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.17it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.1421046406030655, 'eval_precision': 0.6229508196721312, 'eval_recall': 0.7238095238095238, 'eval_f1': 0.669603524229075, 'eval_accuracy': 0.9687945791726106, 'eval_runtime': 2.3773, 'eval_samples_per_second': 20.612, 'eval_steps_per_second': 2.945, 'epoch': 13.0}\n",
            " 26% 962/3700 [18:04<41:37,  1.10it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            "{'loss': 0.0307, 'learning_rate': 1.4594594594594596e-05, 'epoch': 13.51}\n",
            " 27% 1000/3700 [18:46<54:40,  1.22s/it]Saving model checkpoint to test-ner/checkpoint-1000\n",
            "Configuration saved in test-ner/checkpoint-1000/config.json\n",
            "Model weights saved in test-ner/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-1000/special_tokens_map.json\n",
            " 28% 1036/3700 [19:30<44:15,  1.00it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.23it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.96it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  3.00it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.15695923566818237, 'eval_precision': 0.6138211382113821, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6622807017543859, 'eval_accuracy': 0.9673680456490727, 'eval_runtime': 2.4223, 'eval_samples_per_second': 20.229, 'eval_steps_per_second': 2.89, 'epoch': 14.0}\n",
            " 28% 1036/3700 [19:32<44:15,  1.00it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 30% 1110/3700 [20:52<39:48,  1.08it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.14it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.07it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.14265942573547363, 'eval_precision': 0.6234309623430963, 'eval_recall': 0.7095238095238096, 'eval_f1': 0.6636971046770601, 'eval_accuracy': 0.9690620542082738, 'eval_runtime': 2.4254, 'eval_samples_per_second': 20.203, 'eval_steps_per_second': 2.886, 'epoch': 15.0}\n",
            " 30% 1110/3700 [20:55<39:48,  1.08it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 32% 1184/3700 [22:15<41:16,  1.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.29it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.02it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1417326182126999, 'eval_precision': 0.6808510638297872, 'eval_recall': 0.7619047619047619, 'eval_f1': 0.7191011235955055, 'eval_accuracy': 0.9724500713266762, 'eval_runtime': 2.4088, 'eval_samples_per_second': 20.342, 'eval_steps_per_second': 2.906, 'epoch': 16.0}\n",
            " 32% 1184/3700 [22:18<41:16,  1.02it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 34% 1258/3700 [23:38<39:51,  1.02it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.10it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.97it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.14474184811115265, 'eval_precision': 0.6597510373443983, 'eval_recall': 0.7571428571428571, 'eval_f1': 0.70509977827051, 'eval_accuracy': 0.9701319543509273, 'eval_runtime': 2.4133, 'eval_samples_per_second': 20.304, 'eval_steps_per_second': 2.901, 'epoch': 17.0}\n",
            " 34% 1258/3700 [23:40<39:51,  1.02it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 36% 1332/3700 [25:02<41:46,  1.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.37it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.96it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17219093441963196, 'eval_precision': 0.6337448559670782, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.6799116997792494, 'eval_accuracy': 0.9671897289586305, 'eval_runtime': 2.3861, 'eval_samples_per_second': 20.536, 'eval_steps_per_second': 2.934, 'epoch': 18.0}\n",
            " 36% 1332/3700 [25:04<41:46,  1.06s/it]\n",
            "100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n",
            " 38% 1406/3700 [26:25<38:05,  1.00it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.26it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.99it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1681886464357376, 'eval_precision': 0.6401673640167364, 'eval_recall': 0.7285714285714285, 'eval_f1': 0.6815144766146993, 'eval_accuracy': 0.9677246790299572, 'eval_runtime': 2.3796, 'eval_samples_per_second': 20.592, 'eval_steps_per_second': 2.942, 'epoch': 19.0}\n",
            " 38% 1406/3700 [26:27<38:05,  1.00it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 40% 1480/3700 [27:48<33:22,  1.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.28it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.93it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.07it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17884598672389984, 'eval_precision': 0.6188524590163934, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6651982378854625, 'eval_accuracy': 0.9669222539229672, 'eval_runtime': 2.4037, 'eval_samples_per_second': 20.385, 'eval_steps_per_second': 2.912, 'epoch': 20.0}\n",
            " 40% 1480/3700 [27:50<33:22,  1.11it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            "{'loss': 0.0169, 'learning_rate': 1.1891891891891894e-05, 'epoch': 20.27}\n",
            " 41% 1500/3700 [28:12<37:19,  1.02s/it]Saving model checkpoint to test-ner/checkpoint-1500\n",
            "Configuration saved in test-ner/checkpoint-1500/config.json\n",
            "Model weights saved in test-ner/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-1500/special_tokens_map.json\n",
            " 42% 1554/3700 [29:15<32:10,  1.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.27it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.05it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.98it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.15844085812568665, 'eval_precision': 0.6265560165975104, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6696230598669622, 'eval_accuracy': 0.9676355206847361, 'eval_runtime': 2.4145, 'eval_samples_per_second': 20.294, 'eval_steps_per_second': 2.899, 'epoch': 21.0}\n",
            " 42% 1554/3700 [29:18<32:10,  1.11it/s]\n",
            "100% 7/7 [00:02<00:00,  2.98it/s]\u001b[A\n",
            " 44% 1628/3700 [30:38<33:15,  1.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.91it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1553935557603836, 'eval_precision': 0.6452991452991453, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6801801801801802, 'eval_accuracy': 0.9688837375178316, 'eval_runtime': 2.3876, 'eval_samples_per_second': 20.523, 'eval_steps_per_second': 2.932, 'epoch': 22.0}\n",
            " 44% 1628/3700 [30:41<33:15,  1.04it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 46% 1702/3700 [32:02<31:54,  1.04it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.24it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.95it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.06it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.18655745685100555, 'eval_precision': 0.6326530612244898, 'eval_recall': 0.7380952380952381, 'eval_f1': 0.6813186813186813, 'eval_accuracy': 0.9686162624821684, 'eval_runtime': 2.4227, 'eval_samples_per_second': 20.225, 'eval_steps_per_second': 2.889, 'epoch': 23.0}\n",
            " 46% 1702/3700 [32:04<31:54,  1.04it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 48% 1776/3700 [33:26<28:48,  1.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.21it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.97it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17674477398395538, 'eval_precision': 0.6322314049586777, 'eval_recall': 0.7285714285714285, 'eval_f1': 0.6769911504424778, 'eval_accuracy': 0.9681704707560628, 'eval_runtime': 2.3742, 'eval_samples_per_second': 20.639, 'eval_steps_per_second': 2.948, 'epoch': 24.0}\n",
            " 48% 1776/3700 [33:28<28:48,  1.11it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 50% 1850/3700 [34:48<29:17,  1.05it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.20it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.88it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.98it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17085251212120056, 'eval_precision': 0.6260162601626016, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.675438596491228, 'eval_accuracy': 0.9682596291012838, 'eval_runtime': 2.431, 'eval_samples_per_second': 20.156, 'eval_steps_per_second': 2.879, 'epoch': 25.0}\n",
            " 50% 1850/3700 [34:51<29:17,  1.05it/s]\n",
            "100% 7/7 [00:02<00:00,  2.96it/s]\u001b[A\n",
            " 52% 1924/3700 [36:11<26:30,  1.12it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.21it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.96it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.18732914328575134, 'eval_precision': 0.6291666666666667, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6711111111111112, 'eval_accuracy': 0.9673680456490727, 'eval_runtime': 2.4238, 'eval_samples_per_second': 20.216, 'eval_steps_per_second': 2.888, 'epoch': 26.0}\n",
            " 52% 1924/3700 [36:13<26:30,  1.12it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 54% 1998/3700 [37:35<25:09,  1.13it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.15it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.86it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.06it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.18043242394924164, 'eval_precision': 0.6508620689655172, 'eval_recall': 0.719047619047619, 'eval_f1': 0.6832579185520362, 'eval_accuracy': 0.9688837375178316, 'eval_runtime': 2.4557, 'eval_samples_per_second': 19.954, 'eval_steps_per_second': 2.851, 'epoch': 27.0}\n",
            " 54% 1998/3700 [37:37<25:09,  1.13it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            "{'loss': 0.0136, 'learning_rate': 9.189189189189191e-06, 'epoch': 27.03}\n",
            " 54% 2000/3700 [37:40<43:04,  1.52s/it]Saving model checkpoint to test-ner/checkpoint-2000\n",
            "Configuration saved in test-ner/checkpoint-2000/config.json\n",
            "Model weights saved in test-ner/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-2000/special_tokens_map.json\n",
            " 56% 2072/3700 [39:02<24:52,  1.09it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.16it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.86it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.05it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  3.00it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1755353808403015, 'eval_precision': 0.6260162601626016, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.675438596491228, 'eval_accuracy': 0.9697753209700428, 'eval_runtime': 2.396, 'eval_samples_per_second': 20.451, 'eval_steps_per_second': 2.922, 'epoch': 28.0}\n",
            " 56% 2072/3700 [39:05<24:52,  1.09it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 58% 2146/3700 [40:25<24:21,  1.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.29it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.93it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.07it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17083261907100677, 'eval_precision': 0.6302521008403361, 'eval_recall': 0.7142857142857143, 'eval_f1': 0.6696428571428571, 'eval_accuracy': 0.9694186875891584, 'eval_runtime': 2.4081, 'eval_samples_per_second': 20.348, 'eval_steps_per_second': 2.907, 'epoch': 29.0}\n",
            " 58% 2146/3700 [40:28<24:21,  1.06it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 60% 2220/3700 [41:48<22:46,  1.08it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.19it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.92it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.06it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1742953509092331, 'eval_precision': 0.6224066390041494, 'eval_recall': 0.7142857142857143, 'eval_f1': 0.6651884700665188, 'eval_accuracy': 0.9682596291012838, 'eval_runtime': 2.4636, 'eval_samples_per_second': 19.89, 'eval_steps_per_second': 2.841, 'epoch': 30.0}\n",
            " 60% 2220/3700 [41:51<22:46,  1.08it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 62% 2294/3700 [43:11<22:07,  1.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.26it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.94it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.10it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.18676044046878815, 'eval_precision': 0.6553191489361702, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.6921348314606741, 'eval_accuracy': 0.9679921540656206, 'eval_runtime': 2.4827, 'eval_samples_per_second': 19.736, 'eval_steps_per_second': 2.819, 'epoch': 31.0}\n",
            " 62% 2294/3700 [43:14<22:07,  1.06it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 64% 2368/3700 [44:33<18:24,  1.21it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.34it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.02it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17690202593803406, 'eval_precision': 0.6375, 'eval_recall': 0.7285714285714285, 'eval_f1': 0.68, 'eval_accuracy': 0.9682596291012838, 'eval_runtime': 2.4484, 'eval_samples_per_second': 20.013, 'eval_steps_per_second': 2.859, 'epoch': 32.0}\n",
            " 64% 2368/3700 [44:35<18:24,  1.21it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 66% 2442/3700 [45:55<16:38,  1.26it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.37it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.03it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.11it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.18553411960601807, 'eval_precision': 0.6455696202531646, 'eval_recall': 0.7285714285714285, 'eval_f1': 0.6845637583892618, 'eval_accuracy': 0.9689728958630528, 'eval_runtime': 2.4699, 'eval_samples_per_second': 19.839, 'eval_steps_per_second': 2.834, 'epoch': 33.0}\n",
            " 66% 2442/3700 [45:58<16:38,  1.26it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            "{'loss': 0.0109, 'learning_rate': 6.486486486486487e-06, 'epoch': 33.78}\n",
            " 68% 2500/3700 [47:01<22:38,  1.13s/it]Saving model checkpoint to test-ner/checkpoint-2500\n",
            "Configuration saved in test-ner/checkpoint-2500/config.json\n",
            "Model weights saved in test-ner/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-2500/special_tokens_map.json\n",
            " 68% 2516/3700 [47:23<18:09,  1.09it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.26it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.05it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.99it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.99it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.17890550196170807, 'eval_precision': 0.6666666666666666, 'eval_recall': 0.7428571428571429, 'eval_f1': 0.7027027027027027, 'eval_accuracy': 0.9701319543509273, 'eval_runtime': 2.4187, 'eval_samples_per_second': 20.259, 'eval_steps_per_second': 2.894, 'epoch': 34.0}\n",
            " 68% 2516/3700 [47:26<18:09,  1.09it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 70% 2590/3700 [48:46<15:07,  1.22it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.25it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.94it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.19819188117980957, 'eval_precision': 0.6422764227642277, 'eval_recall': 0.7523809523809524, 'eval_f1': 0.6929824561403509, 'eval_accuracy': 0.9677246790299572, 'eval_runtime': 2.3941, 'eval_samples_per_second': 20.467, 'eval_steps_per_second': 2.924, 'epoch': 35.0}\n",
            " 70% 2590/3700 [48:48<15:07,  1.22it/s]\n",
            "100% 7/7 [00:02<00:00,  3.02it/s]\u001b[A\n",
            " 72% 2664/3700 [50:09<14:50,  1.16it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.26it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.95it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.19211578369140625, 'eval_precision': 0.6835443037974683, 'eval_recall': 0.7714285714285715, 'eval_f1': 0.7248322147651006, 'eval_accuracy': 0.9687054208273894, 'eval_runtime': 2.4262, 'eval_samples_per_second': 20.196, 'eval_steps_per_second': 2.885, 'epoch': 36.0}\n",
            " 72% 2664/3700 [50:11<14:50,  1.16it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 74% 2738/3700 [51:32<14:35,  1.10it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.27it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.00it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.19165553152561188, 'eval_precision': 0.6487603305785123, 'eval_recall': 0.7476190476190476, 'eval_f1': 0.6946902654867256, 'eval_accuracy': 0.9694186875891584, 'eval_runtime': 2.4184, 'eval_samples_per_second': 20.261, 'eval_steps_per_second': 2.894, 'epoch': 37.0}\n",
            " 74% 2738/3700 [51:35<14:35,  1.10it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 76% 2812/3700 [52:56<15:41,  1.06s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.28it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.99it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1993934065103531, 'eval_precision': 0.6337448559670782, 'eval_recall': 0.7333333333333333, 'eval_f1': 0.6799116997792494, 'eval_accuracy': 0.9681704707560628, 'eval_runtime': 2.4374, 'eval_samples_per_second': 20.103, 'eval_steps_per_second': 2.872, 'epoch': 38.0}\n",
            " 76% 2812/3700 [52:59<15:41,  1.06s/it]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 78% 2886/3700 [54:19<12:21,  1.10it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.18it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.94it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.19308330118656158, 'eval_precision': 0.6431535269709544, 'eval_recall': 0.7380952380952381, 'eval_f1': 0.6873614190687362, 'eval_accuracy': 0.9694186875891584, 'eval_runtime': 2.4388, 'eval_samples_per_second': 20.092, 'eval_steps_per_second': 2.87, 'epoch': 39.0}\n",
            " 78% 2886/3700 [54:22<12:21,  1.10it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 80% 2960/3700 [55:43<12:53,  1.04s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.08it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.97it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.20093214511871338, 'eval_precision': 0.6300813008130082, 'eval_recall': 0.7380952380952381, 'eval_f1': 0.6798245614035089, 'eval_accuracy': 0.9682596291012838, 'eval_runtime': 2.4225, 'eval_samples_per_second': 20.227, 'eval_steps_per_second': 2.89, 'epoch': 40.0}\n",
            " 80% 2960/3700 [55:45<12:53,  1.04s/it]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            "{'loss': 0.0078, 'learning_rate': 3.7837837837837844e-06, 'epoch': 40.54}\n",
            " 81% 3000/3700 [56:28<12:08,  1.04s/it]Saving model checkpoint to test-ner/checkpoint-3000\n",
            "Configuration saved in test-ner/checkpoint-3000/config.json\n",
            "Model weights saved in test-ner/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-3000/special_tokens_map.json\n",
            " 82% 3034/3700 [57:11<10:28,  1.06it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.23it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.95it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.09it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  3.00it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.18131448328495026, 'eval_precision': 0.6694915254237288, 'eval_recall': 0.7523809523809524, 'eval_f1': 0.7085201793721974, 'eval_accuracy': 0.9690620542082738, 'eval_runtime': 2.4296, 'eval_samples_per_second': 20.168, 'eval_steps_per_second': 2.881, 'epoch': 41.0}\n",
            " 82% 3034/3700 [57:14<10:28,  1.06it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 84% 3108/3700 [58:35<10:00,  1.01s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.20it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.91it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.03it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.1848485916852951, 'eval_precision': 0.6582278481012658, 'eval_recall': 0.7428571428571429, 'eval_f1': 0.697986577181208, 'eval_accuracy': 0.9695078459343794, 'eval_runtime': 2.4096, 'eval_samples_per_second': 20.335, 'eval_steps_per_second': 2.905, 'epoch': 42.0}\n",
            " 84% 3108/3700 [58:37<10:00,  1.01s/it]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 86% 3182/3700 [59:58<07:28,  1.15it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.07it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.05it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.00it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.19116510450839996, 'eval_precision': 0.6431535269709544, 'eval_recall': 0.7380952380952381, 'eval_f1': 0.6873614190687362, 'eval_accuracy': 0.9687945791726106, 'eval_runtime': 2.4157, 'eval_samples_per_second': 20.284, 'eval_steps_per_second': 2.898, 'epoch': 43.0}\n",
            " 86% 3182/3700 [1:00:00<07:28,  1.15it/s]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 88% 3256/3700 [1:01:21<06:30,  1.14it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.20it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.87it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  2.99it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.19610154628753662, 'eval_precision': 0.6356275303643725, 'eval_recall': 0.7476190476190476, 'eval_f1': 0.6870897155361051, 'eval_accuracy': 0.9687054208273894, 'eval_runtime': 2.4354, 'eval_samples_per_second': 20.12, 'eval_steps_per_second': 2.874, 'epoch': 44.0}\n",
            " 88% 3256/3700 [1:01:24<06:30,  1.14it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 90% 3330/3700 [1:02:44<06:40,  1.08s/it]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.27it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.98it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.20093941688537598, 'eval_precision': 0.6473029045643154, 'eval_recall': 0.7428571428571429, 'eval_f1': 0.6917960088691797, 'eval_accuracy': 0.968348787446505, 'eval_runtime': 2.4195, 'eval_samples_per_second': 20.252, 'eval_steps_per_second': 2.893, 'epoch': 45.0}\n",
            " 90% 3330/3700 [1:02:46<06:40,  1.08s/it]\n",
            "100% 7/7 [00:02<00:00,  3.00it/s]\u001b[A\n",
            " 92% 3404/3700 [1:04:06<04:26,  1.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.32it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  5.01it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.10it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.04it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.20076733827590942, 'eval_precision': 0.6527196652719666, 'eval_recall': 0.7428571428571429, 'eval_f1': 0.6948775055679287, 'eval_accuracy': 0.9688837375178316, 'eval_runtime': 2.4492, 'eval_samples_per_second': 20.006, 'eval_steps_per_second': 2.858, 'epoch': 46.0}\n",
            " 92% 3404/3700 [1:04:08<04:26,  1.11it/s]\n",
            "100% 7/7 [00:02<00:00,  3.01it/s]\u001b[A\n",
            " 94% 3478/3700 [1:05:28<03:11,  1.16it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.06it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.92it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.06it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.20045027136802673, 'eval_precision': 0.640495867768595, 'eval_recall': 0.7380952380952381, 'eval_f1': 0.6858407079646018, 'eval_accuracy': 0.9686162624821684, 'eval_runtime': 2.4584, 'eval_samples_per_second': 19.931, 'eval_steps_per_second': 2.847, 'epoch': 47.0}\n",
            " 94% 3478/3700 [1:05:30<03:11,  1.16it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            "{'loss': 0.0085, 'learning_rate': 1.0810810810810812e-06, 'epoch': 47.3}\n",
            " 95% 3500/3700 [1:05:55<03:30,  1.05s/it]Saving model checkpoint to test-ner/checkpoint-3500\n",
            "Configuration saved in test-ner/checkpoint-3500/config.json\n",
            "Model weights saved in test-ner/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in test-ner/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in test-ner/checkpoint-3500/special_tokens_map.json\n",
            " 96% 3552/3700 [1:06:57<02:13,  1.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.30it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.98it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.07it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.02it/s]\u001b[A\n",
            " 86% 6/7 [00:01<00:00,  2.99it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: company seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: address seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: total seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "/usr/local/lib/python3.7/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: date seems not to be NE tag.\n",
            "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.20240698754787445, 'eval_precision': 0.6446280991735537, 'eval_recall': 0.7428571428571429, 'eval_f1': 0.6902654867256637, 'eval_accuracy': 0.9690620542082738, 'eval_runtime': 2.4121, 'eval_samples_per_second': 20.314, 'eval_steps_per_second': 2.902, 'epoch': 48.0}\n",
            " 96% 3552/3700 [1:06:59<02:13,  1.11it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 98% 3626/3700 [1:08:19<01:06,  1.11it/s]The following columns in the evaluation set  don't have a corresponding argument in `LayoutLMForTokenClassification.forward` and have been ignored: tokens, bboxes, ner_tags, id.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49\n",
            "  Batch size = 8\n",
            "\n",
            "  0% 0/7 [00:00<?, ?it/s]\u001b[A\n",
            " 29% 2/7 [00:00<00:00,  7.23it/s]\u001b[A\n",
            " 43% 3/7 [00:00<00:00,  4.90it/s]\u001b[A\n",
            " 57% 4/7 [00:01<00:00,  3.08it/s]\u001b[A\n",
            " 71% 5/7 [00:01<00:00,  3.01it/s]\u001b[A\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 0.20215734839439392, 'eval_precision': 0.6446280991735537, 'eval_recall': 0.7428571428571429, 'eval_f1': 0.6902654867256637, 'eval_accuracy': 0.9689728958630528, 'eval_runtime': 2.4245, 'eval_samples_per_second': 20.21, 'eval_steps_per_second': 2.887, 'epoch': 49.0}\n",
            " 98% 3626/3700 [1:08:22<01:06,  1.11it/s]\n",
            "100% 7/7 [00:02<00:00,  2.99it/s]\u001b[A\n",
            " 99% 3656/3700 [1:08:55<00:50,  1.14s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zrMrCOd0VjBu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}